# ğŸ“˜ Conversational RAG with PDF Uploads  
A Streamlit-based **Conversational Retrieval-Augmented Generation (RAG)** application that lets you:

- Upload **PDF files**
- Automatically extract and index text
- Chat with the content using **Groq LLMs**
- Maintain session-based conversation history
- Retrieve context-aware answers

This project integrates **LangChain**, **ChromaDB**, **Groq**, and **Streamlit** to create a powerful AI assistant capable of understanding long documents.

---


---

## ğŸš€ Features

- ğŸ“„ **Upload multiple PDF files**
- ğŸ¤– **Conversational RAG** with context-aware reformulation
- ğŸ§  **Chat history memory** maintained per session
- âš¡ Uses **Groqâ€™s fast LLMs** via `langchain_groq`
- ğŸ—‚ **Chunking + Embeddings + Vector Search** powered by:
  - `RecursiveCharacterTextSplitter`
  - `OllamaEmbeddings`
  - `Chroma` vector database
- ğŸ¯ Short, precise answers
- ğŸ”‘ Secure API key input in UI

---

## ğŸ§© How It Works

### 1ï¸âƒ£ Upload PDF files  
Documents are extracted using **PyPDFLoader** and split into overlapping chunks.

### 2ï¸âƒ£ Embedding & Indexing  
Chunks are embedded with **OllamaEmbeddings (gemma:2b)** and stored in **ChromaDB**.

### 3ï¸âƒ£ Conversational Retriever  
A â€œhistory-aware retrieverâ€ reformulates queries based on the previous conversation.

### 4ï¸âƒ£ RAG Workflow  
Retrieved context + user question â†’ LLM generates a concise answer.

### 5ï¸âƒ£ Session Memory  
Chat history is stored and reused using:

- `ChatMessageHistory`
- `RunnableWithMessageHistory`




